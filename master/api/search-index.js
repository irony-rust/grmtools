var searchIndex = JSON.parse('{\
"cfgrammar":{"doc":"A library for manipulating Context Free Grammars (CFG). …","i":[[0,"yacc","cfgrammar","",null,null],[0,"ast","cfgrammar::yacc","",null,null],[3,"GrammarAST","cfgrammar::yacc::ast","An AST representing a grammar. This is built up …",null,null],[12,"start","","",0,null],[12,"rules","","",0,null],[12,"prods","","",0,null],[12,"tokens","","",0,null],[12,"precs","","",0,null],[12,"avoid_insert","","",0,null],[12,"implicit_tokens","","",0,null],[12,"parse_param_bindings","","",0,null],[12,"parse_param_lifetimes","","",0,null],[12,"epp","","",0,null],[12,"programs","","",0,null],[3,"Rule","","",null,null],[12,"name","","",1,null],[12,"pidxs","","",1,null],[12,"actiont","","",1,null],[3,"Production","","",null,null],[12,"symbols","","",2,null],[12,"precedence","","",2,null],[12,"action","","",2,null],[4,"Symbol","","",null,null],[13,"Rule","","",3,null],[13,"Token","","",3,null],[4,"GrammarValidationErrorKind","","The various different possible grammar validation errors.",null,null],[13,"NoStartRule","","",4,null],[13,"InvalidStartRule","","",4,null],[13,"UnknownRuleRef","","",4,null],[13,"UnknownToken","","",4,null],[13,"NoPrecForToken","","",4,null],[13,"UnknownEPP","","",4,null],[3,"GrammarValidationError","","<code>GrammarAST</code> validation errors return an instance of this …",null,null],[12,"kind","","",5,null],[12,"sym","","",5,null],[11,"new","","",0,[[],["grammarast",3]]],[11,"add_rule","","",0,[[["string",3],["option",4]]]],[11,"add_prod","","",0,[[["vec",3],["symbol",4],["string",3],["option",4]]]],[11,"add_programs","","",0,[[["string",3]]]],[11,"get_rule","","",0,[[],[["rule",3],["option",4]]]],[11,"has_token","","",0,[[]]],[0,"firsts","cfgrammar::yacc","",null,null],[3,"YaccFirsts","cfgrammar::yacc::firsts","<code>Firsts</code> stores all the first sets for a given grammar. For …",null,null],[11,"new","","Generates and returns the firsts set for the given …",6,[[["yaccgrammar",3]]]],[11,"firsts","","Return all the firsts for rule <code>ridx</code>.",6,[[["ridx",3]],["vob",3]]],[11,"is_set","","Returns true if the token <code>tidx</code> is in the first set for …",6,[[["tidx",3],["ridx",3]]]],[11,"is_epsilon_set","","Returns true if the rule <code>ridx</code> has epsilon in its first …",6,[[["ridx",3]]]],[11,"set","","Ensures that the firsts bit for token <code>tidx</code> rule <code>ridx</code> is …",6,[[["tidx",3],["ridx",3]]]],[0,"follows","cfgrammar::yacc","",null,null],[3,"YaccFollows","cfgrammar::yacc::follows","<code>Follows</code> stores all the Follow sets for a given grammar. …",null,null],[11,"new","","Generates and returns the Follows set for the given …",7,[[["yaccgrammar",3]]]],[11,"follows","","Return the Follows <code>Vob</code> for rule <code>ridx</code>.",7,[[["ridx",3]],["vob",3]]],[11,"is_set","","Returns true if the token <code>tidx</code> is in the follow set for …",7,[[["tidx",3],["ridx",3]]]],[0,"grammar","cfgrammar::yacc","",null,null],[6,"PrecedenceLevel","cfgrammar::yacc::grammar","",null,null],[3,"Precedence","","",null,null],[12,"level","","",8,null],[12,"kind","","",8,null],[4,"AssocKind","","",null,null],[13,"Left","","",9,null],[13,"Right","","",9,null],[13,"Nonassoc","","",9,null],[3,"YaccGrammar","","Representation of a <code>YaccGrammar</code>. See the top-level …",null,null],[11,"new","","",10,[[["yacckind",4]],[["result",4],["yaccgrammarerror",4]]]],[11,"new_with_storaget","","Takes as input a Yacc grammar of <code>YaccKind</code> as a <code>String</code> <code>s</code> …",10,[[["yacckind",4]],[["result",4],["yaccgrammarerror",4]]]],[11,"prods_len","","How many productions does this grammar have?",10,[[],["pidx",3]]],[11,"iter_pidxs","","Return an iterator which produces (in order from …",10,[[]]],[11,"prod","","Get the sequence of symbols for production <code>pidx</code>. Panics …",10,[[["pidx",3]]]],[11,"prod_len","","How many symbols does production <code>pidx</code> have? Panics if <code>pidx</code>…",10,[[["pidx",3]],["sidx",3]]],[11,"prod_to_rule","","Return the rule index of the production <code>pidx</code>. Panics if …",10,[[["pidx",3]],["ridx",3]]],[11,"prod_precedence","","Return the precedence of production <code>pidx</code> (where <code>None</code> …",10,[[["pidx",3]],[["precedence",3],["option",4]]]],[11,"start_prod","","Return the production index of the start rule\'s sole …",10,[[],["pidx",3]]],[11,"rules_len","","How many rules does this grammar have?",10,[[],["ridx",3]]],[11,"iter_rules","","Return an iterator which produces (in order from …",10,[[]]],[11,"rule_to_prods","","Return the productions for rule <code>ridx</code>. Panics if <code>ridx</code> …",10,[[["ridx",3]]]],[11,"rule_name","","Return the name of rule <code>ridx</code>. Panics if <code>ridx</code> doesn\'t …",10,[[["ridx",3]]]],[11,"implicit_rule","","Return the <code>RIdx</code> of the implict rule if it exists, or <code>None</code> …",10,[[],[["option",4],["ridx",3]]]],[11,"rule_idx","","Return the index of the rule named <code>n</code> or <code>None</code> if it …",10,[[],[["option",4],["ridx",3]]]],[11,"start_rule_idx","","What is the index of the start rule? Note that cfgrammar …",10,[[],["ridx",3]]],[11,"tokens_len","","How many tokens does this grammar have?",10,[[],["tidx",3]]],[11,"iter_tidxs","","Return an iterator which produces (in order from …",10,[[]]],[11,"eof_token_idx","","Return the index of the end token.",10,[[],["tidx",3]]],[11,"token_name","","Return the name of token <code>tidx</code> (where <code>None</code> indicates \\\"the …",10,[[["tidx",3]],["option",4]]],[11,"token_precedence","","Return the precedence of token <code>tidx</code> (where <code>None</code> indicates …",10,[[["tidx",3]],[["precedence",3],["option",4]]]],[11,"token_epp","","Return the %epp entry for token <code>tidx</code> (where <code>None</code> …",10,[[["tidx",3]],["option",4]]],[11,"action","","Get the action for production <code>pidx</code>. Panics if <code>pidx</code> …",10,[[["pidx",3]],["option",4]]],[11,"actiontype","","",10,[[["ridx",3]],["option",4]]],[11,"param_args","","",10,[[],["vec",3]]],[11,"param_lifetimes","","",10,[[],["vec",3]]],[11,"programs","","Get the programs part of the grammar",10,[[],["option",4]]],[11,"tokens_map","","Returns a map from names to <code>TIdx</code>s of all tokens that a …",10,[[],[["hashmap",3],["tidx",3]]]],[11,"token_idx","","Return the index of the token named <code>n</code> or <code>None</code> if it …",10,[[],[["tidx",3],["option",4]]]],[11,"avoid_insert","","Is the token <code>tidx</code> marked as <code>%avoid_insert</code>?",10,[[["tidx",3]]]],[11,"has_path","","Is there a path from the <code>from</code> rule to the <code>to</code> rule? Note …",10,[[["ridx",3]]]],[11,"pp_prod","","Returns the string representation of a given production …",10,[[["pidx",3]],["string",3]]],[11,"sentence_generator","","Return a <code>SentenceGenerator</code> which can then generate …",10,[[],["sentencegenerator",3]]],[11,"firsts","","Return a <code>YaccFirsts</code> struct for this grammar.",10,[[],["yaccfirsts",3]]],[11,"follows","","Return a <code>YaccFirsts</code> struct for this grammar.",10,[[],["yaccfollows",3]]],[3,"SentenceGenerator","","A <code>SentenceGenerator</code> can generate minimal sentences for …",null,null],[11,"min_sentence_cost","","What is the cost of a minimal sentence for the rule <code>ridx</code>? …",11,[[["ridx",3]]]],[11,"max_sentence_cost","","What is the cost of a maximal sentence for the rule <code>ridx</code>? …",11,[[["ridx",3]],["option",4]]],[11,"min_sentence","","Non-deterministically return a minimal sentence from the …",11,[[["ridx",3]],[["vec",3],["tidx",3]]]],[11,"min_sentences","","Return (in arbitrary order) all the minimal sentences for …",11,[[["ridx",3]],[["vec",3],["vec",3]]]],[4,"YaccGrammarError","","",null,null],[13,"YaccParserError","","",12,null],[13,"GrammarValidationError","","",12,null],[0,"parser","cfgrammar::yacc","",null,null],[4,"YaccParserErrorKind","cfgrammar::yacc::parser","The various different possible Yacc parser errors.",null,null],[13,"IllegalName","","",13,null],[13,"IllegalString","","",13,null],[13,"IncompleteRule","","",13,null],[13,"DuplicateRule","","",13,null],[13,"IncompleteComment","","",13,null],[13,"IncompleteAction","","",13,null],[13,"MissingColon","","",13,null],[13,"MissingRightArrow","","",13,null],[13,"MismatchedBrace","","",13,null],[13,"PrematureEnd","","",13,null],[13,"ProgramsNotSupported","","",13,null],[13,"UnknownDeclaration","","",13,null],[13,"DuplicatePrecedence","","",13,null],[13,"PrecNotFollowedByToken","","",13,null],[13,"DuplicateAvoidInsertDeclaration","","",13,null],[13,"DuplicateImplicitTokensDeclaration","","",13,null],[13,"DuplicateStartDeclaration","","",13,null],[13,"DuplicateActiontypeDeclaration","","",13,null],[13,"DuplicateEPP","","",13,null],[13,"ReachedEOL","","",13,null],[13,"InvalidString","","",13,null],[3,"YaccParserError","","Any error from the Yacc parser returns an instance of …",null,null],[12,"kind","","",14,null],[4,"YaccKind","cfgrammar::yacc","The particular Yacc variant this grammar makes use of.",null,null],[13,"Original","","The original Yacc style as documented by Johnson,",15,null],[13,"Grmtools","","Similar to the original Yacc style, but allowing …",15,null],[13,"Eco","","The variant used in the Eco language composition editor",15,null],[4,"YaccOriginalActionKind","","",null,null],[13,"UserAction","","Execute user-specified actions attached to each …",16,null],[13,"GenericParseTree","","Automatically create a parse tree instead of …",16,null],[13,"NoAction","","Do not do execute actions of any sort.",16,null],[3,"PIdx","cfgrammar","A type specifically for production indices (e.g. a rule …",null,null],[12,"0","","",17,null],[3,"RIdx","","A type specifically for rule indices.",null,null],[12,"0","","",18,null],[3,"SIdx","","A type specifically for symbol indices (within a …",null,null],[12,"0","","",19,null],[3,"TIdx","","A type specifically for token indices.",null,null],[12,"0","","",20,null],[4,"Symbol","","",null,null],[13,"Rule","","",21,null],[13,"Token","","",21,null],[11,"from","","",18,[[]]],[11,"into","","",18,[[]]],[11,"to_owned","","",18,[[]]],[11,"clone_into","","",18,[[]]],[11,"borrow","","",18,[[]]],[11,"borrow_mut","","",18,[[]]],[11,"try_from","","",18,[[],["result",4]]],[11,"try_into","","",18,[[],["result",4]]],[11,"type_id","","",18,[[],["typeid",3]]],[11,"equivalent","","",18,[[]]],[11,"from","","",17,[[]]],[11,"into","","",17,[[]]],[11,"to_owned","","",17,[[]]],[11,"clone_into","","",17,[[]]],[11,"borrow","","",17,[[]]],[11,"borrow_mut","","",17,[[]]],[11,"try_from","","",17,[[],["result",4]]],[11,"try_into","","",17,[[],["result",4]]],[11,"type_id","","",17,[[],["typeid",3]]],[11,"equivalent","","",17,[[]]],[11,"from","","",19,[[]]],[11,"into","","",19,[[]]],[11,"to_owned","","",19,[[]]],[11,"clone_into","","",19,[[]]],[11,"borrow","","",19,[[]]],[11,"borrow_mut","","",19,[[]]],[11,"try_from","","",19,[[],["result",4]]],[11,"try_into","","",19,[[],["result",4]]],[11,"type_id","","",19,[[],["typeid",3]]],[11,"equivalent","","",19,[[]]],[11,"from","","",20,[[]]],[11,"into","","",20,[[]]],[11,"to_owned","","",20,[[]]],[11,"clone_into","","",20,[[]]],[11,"borrow","","",20,[[]]],[11,"borrow_mut","","",20,[[]]],[11,"try_from","","",20,[[],["result",4]]],[11,"try_into","","",20,[[],["result",4]]],[11,"type_id","","",20,[[],["typeid",3]]],[11,"equivalent","","",20,[[]]],[11,"from","cfgrammar::yacc::ast","",0,[[]]],[11,"into","","",0,[[]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"equivalent","","",2,[[]]],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"to_owned","","",3,[[]]],[11,"clone_into","","",3,[[]]],[11,"to_string","","",3,[[],["string",3]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"equivalent","","",3,[[]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"from","","",5,[[]]],[11,"into","","",5,[[]]],[11,"to_string","","",5,[[],["string",3]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::firsts","",6,[[]]],[11,"into","","",6,[[]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::follows","",7,[[]]],[11,"into","","",7,[[]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::grammar","",8,[[]]],[11,"into","","",8,[[]]],[11,"to_owned","","",8,[[]]],[11,"clone_into","","",8,[[]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"from","","",9,[[]]],[11,"into","","",9,[[]]],[11,"to_owned","","",9,[[]]],[11,"clone_into","","",9,[[]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"from","","",10,[[]]],[11,"into","","",10,[[]]],[11,"borrow","","",10,[[]]],[11,"borrow_mut","","",10,[[]]],[11,"try_from","","",10,[[],["result",4]]],[11,"try_into","","",10,[[],["result",4]]],[11,"type_id","","",10,[[],["typeid",3]]],[11,"from","","",11,[[]]],[11,"into","","",11,[[]]],[11,"borrow","","",11,[[]]],[11,"borrow_mut","","",11,[[]]],[11,"try_from","","",11,[[],["result",4]]],[11,"try_into","","",11,[[],["result",4]]],[11,"type_id","","",11,[[],["typeid",3]]],[11,"from","","",12,[[]]],[11,"into","","",12,[[]]],[11,"to_string","","",12,[[],["string",3]]],[11,"borrow","","",12,[[]]],[11,"borrow_mut","","",12,[[]]],[11,"try_from","","",12,[[],["result",4]]],[11,"try_into","","",12,[[],["result",4]]],[11,"type_id","","",12,[[],["typeid",3]]],[11,"from","cfgrammar::yacc::parser","",13,[[]]],[11,"into","","",13,[[]]],[11,"borrow","","",13,[[]]],[11,"borrow_mut","","",13,[[]]],[11,"try_from","","",13,[[],["result",4]]],[11,"try_into","","",13,[[],["result",4]]],[11,"type_id","","",13,[[],["typeid",3]]],[11,"from","","",14,[[]]],[11,"into","","",14,[[]]],[11,"to_string","","",14,[[],["string",3]]],[11,"borrow","","",14,[[]]],[11,"borrow_mut","","",14,[[]]],[11,"try_from","","",14,[[],["result",4]]],[11,"try_into","","",14,[[],["result",4]]],[11,"type_id","","",14,[[],["typeid",3]]],[11,"from","cfgrammar::yacc","",15,[[]]],[11,"into","","",15,[[]]],[11,"to_owned","","",15,[[]]],[11,"clone_into","","",15,[[]]],[11,"borrow","","",15,[[]]],[11,"borrow_mut","","",15,[[]]],[11,"try_from","","",15,[[],["result",4]]],[11,"try_into","","",15,[[],["result",4]]],[11,"type_id","","",15,[[],["typeid",3]]],[11,"from","","",16,[[]]],[11,"into","","",16,[[]]],[11,"to_owned","","",16,[[]]],[11,"clone_into","","",16,[[]]],[11,"borrow","","",16,[[]]],[11,"borrow_mut","","",16,[[]]],[11,"try_from","","",16,[[],["result",4]]],[11,"try_into","","",16,[[],["result",4]]],[11,"type_id","","",16,[[],["typeid",3]]],[11,"from","cfgrammar","",21,[[]]],[11,"into","","",21,[[]]],[11,"to_owned","","",21,[[]]],[11,"clone_into","","",21,[[]]],[11,"borrow","","",21,[[]]],[11,"borrow_mut","","",21,[[]]],[11,"try_from","","",21,[[],["result",4]]],[11,"try_into","","",21,[[],["result",4]]],[11,"type_id","","",21,[[],["typeid",3]]],[11,"equivalent","","",21,[[]]],[11,"from","cfgrammar::yacc::grammar","",12,[[["yaccparsererror",3]],["yaccgrammarerror",4]]],[11,"from","","",12,[[["grammarvalidationerror",3]],["yaccgrammarerror",4]]],[11,"clone","cfgrammar","",18,[[],["ridx",3]]],[11,"clone","","",17,[[],["pidx",3]]],[11,"clone","","",19,[[],["sidx",3]]],[11,"clone","","",20,[[],["tidx",3]]],[11,"clone","cfgrammar::yacc::ast","",3,[[],["symbol",4]]],[11,"clone","cfgrammar::yacc::grammar","",8,[[],["precedence",3]]],[11,"clone","","",9,[[],["assockind",4]]],[11,"clone","cfgrammar::yacc","",15,[[],["yacckind",4]]],[11,"clone","","",16,[[],["yaccoriginalactionkind",4]]],[11,"clone","cfgrammar","",21,[[],["symbol",4]]],[11,"cmp","","",18,[[["ridx",3]],["ordering",4]]],[11,"cmp","","",17,[[["pidx",3]],["ordering",4]]],[11,"cmp","","",19,[[["sidx",3]],["ordering",4]]],[11,"cmp","","",20,[[["tidx",3]],["ordering",4]]],[11,"eq","","",18,[[["ridx",3]]]],[11,"ne","","",18,[[["ridx",3]]]],[11,"eq","","",17,[[["pidx",3]]]],[11,"ne","","",17,[[["pidx",3]]]],[11,"eq","","",19,[[["sidx",3]]]],[11,"ne","","",19,[[["sidx",3]]]],[11,"eq","","",20,[[["tidx",3]]]],[11,"ne","","",20,[[["tidx",3]]]],[11,"eq","cfgrammar::yacc::ast","",2,[[["production",3]]]],[11,"ne","","",2,[[["production",3]]]],[11,"eq","","",3,[[["symbol",4]]]],[11,"ne","","",3,[[["symbol",4]]]],[11,"eq","cfgrammar::yacc::grammar","",8,[[["precedence",3]]]],[11,"ne","","",8,[[["precedence",3]]]],[11,"eq","","",9,[[["assockind",4]]]],[11,"eq","cfgrammar","",21,[[["symbol",4]]]],[11,"ne","","",21,[[["symbol",4]]]],[11,"partial_cmp","","",18,[[["ridx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",18,[[["ridx",3]]]],[11,"le","","",18,[[["ridx",3]]]],[11,"gt","","",18,[[["ridx",3]]]],[11,"ge","","",18,[[["ridx",3]]]],[11,"partial_cmp","","",17,[[["pidx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",17,[[["pidx",3]]]],[11,"le","","",17,[[["pidx",3]]]],[11,"gt","","",17,[[["pidx",3]]]],[11,"ge","","",17,[[["pidx",3]]]],[11,"partial_cmp","","",19,[[["sidx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",19,[[["sidx",3]]]],[11,"le","","",19,[[["sidx",3]]]],[11,"gt","","",19,[[["sidx",3]]]],[11,"ge","","",19,[[["sidx",3]]]],[11,"partial_cmp","","",20,[[["tidx",3]],[["option",4],["ordering",4]]]],[11,"lt","","",20,[[["tidx",3]]]],[11,"le","","",20,[[["tidx",3]]]],[11,"gt","","",20,[[["tidx",3]]]],[11,"ge","","",20,[[["tidx",3]]]],[11,"fmt","","",18,[[["formatter",3]],["result",6]]],[11,"fmt","","",17,[[["formatter",3]],["result",6]]],[11,"fmt","","",19,[[["formatter",3]],["result",6]]],[11,"fmt","","",20,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::ast","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"fmt","","",4,[[["formatter",3]],["result",6]]],[11,"fmt","","",5,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::firsts","",6,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::follows","",7,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::grammar","",8,[[["formatter",3]],["result",6]]],[11,"fmt","","",9,[[["formatter",3]],["result",6]]],[11,"fmt","","",12,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::parser","",13,[[["formatter",3]],["result",6]]],[11,"fmt","","",14,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc","",15,[[["formatter",3]],["result",6]]],[11,"fmt","","",16,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar","",21,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::ast","",5,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::grammar","",12,[[["formatter",3]],["result",6]]],[11,"fmt","cfgrammar::yacc::parser","",14,[[["formatter",3]],["result",6]]],[11,"hash","cfgrammar","",18,[[]]],[11,"hash","","",17,[[]]],[11,"hash","","",19,[[]]],[11,"hash","","",20,[[]]],[11,"hash","cfgrammar::yacc::ast","",3,[[]]],[11,"hash","cfgrammar","",21,[[]]],[11,"serialize","","",18,[[],["result",4]]],[11,"serialize","","",17,[[],["result",4]]],[11,"serialize","","",19,[[],["result",4]]],[11,"serialize","","",20,[[],["result",4]]],[11,"serialize","cfgrammar::yacc::grammar","",8,[[],["result",4]]],[11,"serialize","","",9,[[],["result",4]]],[11,"serialize","","",10,[[],["result",4]]],[11,"serialize","cfgrammar","",21,[[],["result",4]]],[11,"deserialize","","",18,[[],["result",4]]],[11,"deserialize","","",17,[[],["result",4]]],[11,"deserialize","","",19,[[],["result",4]]],[11,"deserialize","","",20,[[],["result",4]]],[11,"deserialize","cfgrammar::yacc::grammar","",8,[[],["result",4]]],[11,"deserialize","","",9,[[],["result",4]]],[11,"deserialize","","",10,[[],["result",4]]],[11,"deserialize","cfgrammar","",21,[[],["result",4]]],[11,"as_storaget","","",18,[[]]],[11,"as_storaget","","",17,[[]]],[11,"as_storaget","","",19,[[]]],[11,"as_storaget","","",20,[[]]]],"p":[[3,"GrammarAST"],[3,"Rule"],[3,"Production"],[4,"Symbol"],[4,"GrammarValidationErrorKind"],[3,"GrammarValidationError"],[3,"YaccFirsts"],[3,"YaccFollows"],[3,"Precedence"],[4,"AssocKind"],[3,"YaccGrammar"],[3,"SentenceGenerator"],[4,"YaccGrammarError"],[4,"YaccParserErrorKind"],[3,"YaccParserError"],[4,"YaccKind"],[4,"YaccOriginalActionKind"],[3,"PIdx"],[3,"RIdx"],[3,"SIdx"],[3,"TIdx"],[4,"Symbol"]]},\
"lrlex":{"doc":"<code>lrlex</code> is a partial replacement for <code>lex</code> / <code>flex</code>. It takes …","i":[[3,"LexerBuilder","lrlex","A <code>LexerBuilder</code> allows one to specify the criteria for …",null,null],[4,"LexerKind","","",null,null],[13,"LRNonStreamingLexer","","",0,null],[4,"Visibility","","Specify the visibility of the module generated by …",null,null],[13,"Private","","Module-level visibility only.",1,null],[13,"Public","","<code>pub</code>",1,null],[13,"PublicSuper","","<code>pub(super)</code>",1,null],[13,"PublicSelf","","<code>pub(self)</code>",1,null],[13,"PublicCrate","","<code>pub(crate)</code>",1,null],[13,"PublicIn","","<code>pub(in {arg})</code>",1,null],[3,"LRNonStreamingLexer","","An <code>LRNonStreamingLexer</code> holds a reference to a string and …",null,null],[3,"LRNonStreamingLexerDef","","This struct represents, in essence, a .l file in memory. …",null,null],[8,"LexerDef","","Methods which all lexer definitions must implement.",null,null],[10,"from_str","","Instantiate a lexer from a string (e.g. representing a <code>.l</code> …",2,[[],["lexbuildresult",6]]],[10,"get_rule","","Get the <code>Rule</code> at index <code>idx</code>.",2,[[],[["rule",3],["option",4]]]],[10,"get_rule_by_id","","Get the <code>Rule</code> instance associated with a particular lexeme …",2,[[],["rule",3]]],[10,"get_rule_by_name","","Get the <code>Rule</code> instance associated with a particular name.",2,[[],[["rule",3],["option",4]]]],[10,"set_rule_ids","","Set the id attribute on rules to the corresponding value …",2,[[["hashmap",3]]]],[10,"iter_rules","","Returns an iterator over all rules in this AST.",2,[[],[["rule",3],["iter",3]]]],[6,"LexBuildResult","","",null,null],[3,"LexBuildError","","Any error from the Lex parser returns an instance of this …",null,null],[12,"kind","","",3,null],[4,"LexErrorKind","","The various different possible Lex parser errors.",null,null],[13,"PrematureEnd","","",4,null],[13,"RoutinesNotSupported","","",4,null],[13,"UnknownDeclaration","","",4,null],[13,"MissingSpace","","",4,null],[13,"InvalidName","","",4,null],[13,"DuplicateName","","",4,null],[13,"RegexError","","",4,null],[5,"build_lex","","",null,[[],[["lrnonstreaminglexerdef",3],["lexbuilderror",3],["result",4]]]],[6,"NonStreamingLexerDef","","",null,null],[14,"lrlex_mod","","A convenience macro for including statically compiled <code>.l</code> …",null,null],[11,"from","","",0,[[]]],[11,"into","","",0,[[]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"try_into","","",0,[[],["result",4]]],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"to_owned","","",1,[[]]],[11,"clone_into","","",1,[[]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"try_into","","",1,[[],["result",4]]],[11,"equivalent","","",1,[[]]],[11,"from","","",5,[[]]],[11,"into","","",5,[[]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"try_into","","",5,[[],["result",4]]],[11,"from","","",6,[[]]],[11,"into","","",6,[[]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"try_into","","",6,[[],["result",4]]],[11,"from","","",7,[[]]],[11,"into","","",7,[[]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"try_into","","",7,[[],["result",4]]],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"to_string","","",3,[[],["string",3]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"try_into","","",3,[[],["result",4]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"try_into","","",4,[[],["result",4]]],[11,"from_rules","","",6,[[["rule",3],["vec",3]],["lrnonstreaminglexerdef",3]]],[11,"from_str","","",6,[[],[["lrnonstreaminglexerdef",3],["lexbuildresult",6]]]],[11,"get_rule","","",6,[[],[["rule",3],["option",4]]]],[11,"get_rule_by_id","","",6,[[],["rule",3]]],[11,"get_rule_by_name","","",6,[[],[["rule",3],["option",4]]]],[11,"set_rule_ids","","",6,[[["hashmap",3]]]],[11,"iter_rules","","",6,[[],[["rule",3],["iter",3]]]],[11,"clone","","",1,[[],["visibility",4]]],[11,"eq","","",1,[[["visibility",4]]]],[11,"ne","","",1,[[["visibility",4]]]],[11,"fmt","","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"fmt","","",4,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"iter","","",7,[[],[["box",3],["iterator",8]]]],[11,"span_str","","",7,[[["span",3]]]],[11,"span_lines_str","","",7,[[["span",3]]]],[11,"line_col","","",7,[[["span",3]]]],[11,"new","","Create a new <code>LexerBuilder</code>.",5,[[]]],[11,"lexerkind","","Set the type of lexer to be generated to <code>lexerkind</code>.",5,[[["lexerkind",4]]]],[11,"mod_name","","Set the generated module name to <code>mod_name</code>. If no module …",5,[[]]],[11,"visibility","","Set the visibility of the generated module to <code>vis</code>. …",5,[[["visibility",4]]]],[11,"rule_ids_map","","Set this lexer builder\'s map of rule IDs to <code>rule_ids_map</code>. …",5,[[["hashmap",3],["string",3]]]],[11,"process_file_in_src","","Given the filename <code>a/b.l</code> as input, statically compile the …",5,[[],[["result",4],["box",3]]]],[11,"process_file","","Statically compile the <code>.l</code> file <code>inp</code> into Rust, placing the …",5,[[],[["result",4],["box",3]]]],[11,"allow_missing_terms_in_lexer","","If passed false, tokens used in the grammar but not …",5,[[]]],[11,"allow_missing_tokens_in_parser","","If passed false, tokens defined in the lexer but not used …",5,[[]]],[11,"lexer","","Return an [LRNonStreamingLexer] for the <code>String</code> <code>s</code> that …",6,[[],["lrnonstreaminglexer",3]]]],"p":[[4,"LexerKind"],[4,"Visibility"],[8,"LexerDef"],[3,"LexBuildError"],[4,"LexErrorKind"],[3,"LexerBuilder"],[3,"LRNonStreamingLexerDef"],[3,"LRNonStreamingLexer"]]},\
"lrpar":{"doc":"<code>lrpar</code> provides a Yacc-compatible parser (where grammars …","i":[[3,"LexError","lrpar","A Lexing error.",null,null],[3,"Lexeme","","A <code>Lexeme</code> represents a segment of the user\'s input that …",null,null],[8,"Lexer","","The base trait which all lexers which want to interact …",null,null],[10,"iter","","Iterate over all the lexemes in this lexer. Note that:",0,[[],[["box",3],["iterator",8]]]],[8,"NonStreamingLexer","","A <code>NonStreamingLexer</code> is one that takes input in one go, …",null,null],[10,"span_str","","Return the user input associated with a [Span].",1,[[["span",3]]]],[10,"span_lines_str","","Return the lines containing the input at <code>span</code> (including <em>…",1,[[["span",3]]]],[10,"line_col","","Return …",1,[[["span",3]]]],[3,"CTParserBuilder","","A <code>CTParserBuilder</code> allows one to specify the criteria for …",null,null],[4,"Visibility","","Specify the visibility of the module generated by …",null,null],[13,"Private","","Module-level visibility only.",2,null],[13,"Public","","<code>pub</code>",2,null],[13,"PublicSuper","","<code>pub(super)</code>",2,null],[13,"PublicSelf","","<code>pub(self)</code>",2,null],[13,"PublicCrate","","<code>pub(crate)</code>",2,null],[13,"PublicIn","","<code>pub(in {arg})</code>",2,null],[4,"LexParseError","","A lexing or parsing error. Although the two are quite …",null,null],[13,"LexError","","",3,null],[13,"ParseError","","",3,null],[4,"Node","","A generic parse tree.",null,null],[13,"Term","","Terminals store a single lexeme.",4,null],[12,"lexeme","lrpar::Node","",5,null],[13,"Nonterm","lrpar","Nonterminals reference a rule and have zero or more <code>Node</code>s …",4,null],[12,"ridx","lrpar::Node","",6,null],[12,"nodes","","",6,null],[3,"ParseError","lrpar","Records a single parse error.",null,null],[4,"ParseRepair","","After a parse error is encountered, the parser attempts …",null,null],[13,"Insert","","Insert a <code>Symbol::Token</code>.",7,null],[13,"Delete","","Delete a symbol.",7,null],[13,"Shift","","Shift a symbol.",7,null],[3,"RTParserBuilder","","A run-time parser builder.",null,null],[4,"RecoveryKind","","What recovery algorithm should be used when a syntax …",null,null],[13,"CPCTPlus","","The CPCT+ algorithm from Diekmann/Tratt \\\"Don\'t Panic! …",8,null],[13,"None","","Don\'t use error recovery: return as soon as the first …",8,null],[3,"Span","","A <code>Span</code> records what portion of the user\'s input something …",null,null],[11,"new","","Create a new span starting at byte <code>start</code> and ending at …",9,[[]]],[11,"start","","Byte offset of the start of the span.",9,[[]]],[11,"end","","Byte offset of the end of the span.",9,[[]]],[11,"len","","Length in bytes of the span.",9,[[]]],[11,"is_empty","","Returns <code>true</code> if this <code>Span</code> covers 0 bytes, or <code>false</code> …",9,[[]]],[14,"lrpar_mod","","A convenience macro for including statically compiled <code>.y</code> …",null,null],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"to_owned","","",2,[[]]],[11,"clone_into","","",2,[[]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"equivalent","","",2,[[]]],[11,"try_into","","",2,[[],["result",4]]],[11,"from","","",10,[[]]],[11,"into","","",10,[[]]],[11,"borrow","","",10,[[]]],[11,"borrow_mut","","",10,[[]]],[11,"try_from","","",10,[[],["result",4]]],[11,"try_into","","",10,[[],["result",4]]],[11,"type_id","","",10,[[],["typeid",3]]],[11,"try_into","","",10,[[],["result",4]]],[11,"from","","",11,[[]]],[11,"into","","",11,[[]]],[11,"to_owned","","",11,[[]]],[11,"clone_into","","",11,[[]]],[11,"to_string","","",11,[[],["string",3]]],[11,"borrow","","",11,[[]]],[11,"borrow_mut","","",11,[[]]],[11,"try_from","","",11,[[],["result",4]]],[11,"try_into","","",11,[[],["result",4]]],[11,"type_id","","",11,[[],["typeid",3]]],[11,"try_into","","",11,[[],["result",4]]],[11,"from","","",12,[[]]],[11,"into","","",12,[[]]],[11,"to_owned","","",12,[[]]],[11,"clone_into","","",12,[[]]],[11,"to_string","","",12,[[],["string",3]]],[11,"borrow","","",12,[[]]],[11,"borrow_mut","","",12,[[]]],[11,"try_from","","",12,[[],["result",4]]],[11,"try_into","","",12,[[],["result",4]]],[11,"type_id","","",12,[[],["typeid",3]]],[11,"equivalent","","",12,[[]]],[11,"try_into","","",12,[[],["result",4]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"to_owned","","",4,[[]]],[11,"clone_into","","",4,[[]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"try_into","","",4,[[],["result",4]]],[11,"from","","",8,[[]]],[11,"into","","",8,[[]]],[11,"to_owned","","",8,[[]]],[11,"clone_into","","",8,[[]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"try_into","","",8,[[],["result",4]]],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"to_string","","",3,[[],["string",3]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"try_into","","",3,[[],["result",4]]],[11,"from","","",13,[[]]],[11,"into","","",13,[[]]],[11,"borrow","","",13,[[]]],[11,"borrow_mut","","",13,[[]]],[11,"try_from","","",13,[[],["result",4]]],[11,"try_into","","",13,[[],["result",4]]],[11,"type_id","","",13,[[],["typeid",3]]],[11,"try_into","","",13,[[],["result",4]]],[11,"from","","",7,[[]]],[11,"into","","",7,[[]]],[11,"to_owned","","",7,[[]]],[11,"clone_into","","",7,[[]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"equivalent","","",7,[[]]],[11,"try_into","","",7,[[],["result",4]]],[11,"from","","",14,[[]]],[11,"into","","",14,[[]]],[11,"to_owned","","",14,[[]]],[11,"clone_into","","",14,[[]]],[11,"to_string","","",14,[[],["string",3]]],[11,"borrow","","",14,[[]]],[11,"borrow_mut","","",14,[[]]],[11,"try_from","","",14,[[],["result",4]]],[11,"try_into","","",14,[[],["result",4]]],[11,"type_id","","",14,[[],["typeid",3]]],[11,"try_into","","",14,[[],["result",4]]],[11,"from","","",9,[[]]],[11,"into","","",9,[[]]],[11,"to_owned","","",9,[[]]],[11,"clone_into","","",9,[[]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"equivalent","","",9,[[]]],[11,"try_into","","",9,[[],["result",4]]],[11,"from","","",3,[[["lexerror",3]],["lexparseerror",4]]],[11,"from","","",3,[[["parseerror",3]],["lexparseerror",4]]],[11,"clone","","",2,[[],["visibility",4]]],[11,"clone","","",11,[[],["lexerror",3]]],[11,"clone","","",12,[[],["lexeme",3]]],[11,"clone","","",4,[[],["node",4]]],[11,"clone","","",8,[[],["recoverykind",4]]],[11,"clone","","",7,[[],["parserepair",4]]],[11,"clone","","",14,[[],["parseerror",3]]],[11,"clone","","",9,[[],["span",3]]],[11,"eq","","",2,[[["visibility",4]]]],[11,"ne","","",2,[[["visibility",4]]]],[11,"eq","","",12,[[["lexeme",3]]]],[11,"ne","","",12,[[["lexeme",3]]]],[11,"eq","","",4,[[["node",4]]]],[11,"ne","","",4,[[["node",4]]]],[11,"eq","","",7,[[["parserepair",4]]]],[11,"ne","","",7,[[["parserepair",4]]]],[11,"eq","","",14,[[["parseerror",3]]]],[11,"ne","","",14,[[["parseerror",3]]]],[11,"eq","","",9,[[["span",3]]]],[11,"ne","","",9,[[["span",3]]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","","",11,[[["formatter",3]],["result",6]]],[11,"fmt","","",12,[[["formatter",3]],["result",6]]],[11,"fmt","","",4,[[["formatter",3]],["result",6]]],[11,"fmt","","",8,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"fmt","","",7,[[["formatter",3]],["result",6]]],[11,"fmt","","",14,[[["formatter",3]],["result",6]]],[11,"fmt","","",9,[[["formatter",3]],["result",6]]],[11,"fmt","","",11,[[["formatter",3]],["result",6]]],[11,"fmt","","",12,[[["formatter",3]],["result",6]]],[11,"fmt","","",3,[[["formatter",3]],["result",6]]],[11,"fmt","","",14,[[["formatter",3]],["result",6]]],[11,"hash","","",12,[[]]],[11,"hash","","",7,[[]]],[11,"new","","Create a new <code>CTParserBuilder</code>.",10,[[]]],[11,"new_with_storaget","","Create a new <code>CTParserBuilder</code>.",10,[[]]],[11,"mod_name","","Set the generated module name to <code>mod_name</code>. If no module …",10,[[]]],[11,"visibility","","Set the visibility of the generated module to <code>vis</code>. …",10,[[["visibility",4]]]],[11,"recoverer","","Set the recoverer for this parser to <code>rk</code>. Defaults to …",10,[[["recoverykind",4]]]],[11,"yacckind","","Set the <code>YaccKind</code> for this parser to <code>ak</code>.",10,[[["yacckind",4]]]],[11,"error_on_conflicts","","If set to true, <code>process_file_in_src</code> will return an error …",10,[[]]],[11,"conflicts","","If there are any conflicts in the grammar, return a tuple …",10,[[],["option",4]]],[11,"process_file_in_src","","Given the filename <code>a/b.y</code> as input, statically compile the …",10,[[],[["result",4],["hashmap",3],["box",3]]]],[11,"process_file","","Statically compile the Yacc file <code>inp</code> into Rust, placing …",10,[[],[["result",4],["hashmap",3],["box",3]]]],[11,"new","","",11,[[["span",3]]]],[11,"span","","",11,[[],["span",3]]],[11,"new","","Create a new token with ID <code>tok_id</code> and a starting position …",12,[[["option",4]]]],[11,"tok_id","","The token ID.",12,[[]]],[11,"start","","Byte offset of the start of the lexeme",12,[[]]],[11,"end","","Byte offset of the end of the lexeme.",12,[[]]],[11,"len","","Length in bytes of the lexeme.",12,[[]]],[11,"span","","Obtain this <code>Lexeme</code>\'s [Span].",12,[[],["span",3]]],[11,"inserted","","Returns <code>true</code> if this lexeme was inserted as the result of …",12,[[]]],[11,"pp","","Return a pretty-printed version of this node.",4,[[["yaccgrammar",3]],["string",3]]],[11,"pp","","A pretty-printer of a lexer/parser error. This isn\'t …",3,[[["nonstreaminglexer",8],["fn",8]],["string",3]]],[11,"new","","Create a new run-time parser from a <code>YaccGrammar</code>, a …",13,[[["statetable",3],["yaccgrammar",3]]]],[11,"recoverer","","Set the recoverer for this parser to <code>rk</code>.",13,[[["recoverykind",4]]]],[11,"term_costs","","",13,[[["fn",8]]]],[11,"parse_generictree","","Parse input, and (if possible) return a generic parse …",13,[[["nonstreaminglexer",8]]]],[11,"parse_noaction","","Parse input, returning any errors found. See the …",13,[[["nonstreaminglexer",8]],[["vec",3],["lexparseerror",4]]]],[11,"parse_actions","","Parse input, execute actions, and return the associated …",13,[[["nonstreaminglexer",8]]]],[11,"stidx","","Return the state table index where this error was …",14,[[],["stidx",3]]],[11,"lexeme","","Return the lexeme where this error was detected.",14,[[],["lexeme",3]]],[11,"repairs","","Return the repairs found that would fix this error. Note …",14,[[],["vec",3]]]],"p":[[8,"Lexer"],[8,"NonStreamingLexer"],[4,"Visibility"],[4,"LexParseError"],[4,"Node"],[13,"Term"],[13,"Nonterm"],[4,"ParseRepair"],[4,"RecoveryKind"],[3,"Span"],[3,"CTParserBuilder"],[3,"LexError"],[3,"Lexeme"],[3,"RTParserBuilder"],[3,"ParseError"]]},\
"lrpar_tests":{"doc":"","i":[],"p":[]},\
"lrtable":{"doc":"","i":[[0,"statetable","lrtable","",null,null],[3,"Conflicts","lrtable::statetable","",null,null],[11,"sr_conflicts","","Return an iterator over all shift/reduce conflicts.",0,[[]]],[11,"rr_conflicts","","Return an iterator over all reduce/reduce conflicts.",0,[[]]],[11,"sr_len","","How many shift/reduce conflicts are there?",0,[[]]],[11,"rr_len","","How many reduce/reduce conflicts are there?",0,[[]]],[11,"pp","","Returns a pretty-printed version of the conflicts.",0,[[["yaccgrammar",3]],["string",3]]],[4,"StateTableErrorKind","","The various different possible Yacc parser errors.",null,null],[13,"AcceptReduceConflict","","",1,null],[3,"StateTableError","","Any error from the Yacc parser returns an instance of …",null,null],[12,"kind","","",2,null],[12,"pidx","","",2,null],[3,"StateTable","","A representation of a <code>StateTable</code> for a grammar. <code>actions</code> …",null,null],[12,"final_state","","",3,null],[4,"Action","","",null,null],[13,"Shift","","Shift to state X in the statetable.",4,null],[13,"Reduce","","Reduce production X in the grammar.",4,null],[13,"Accept","","Accept this input.",4,null],[13,"Error","","No valid action.",4,null],[11,"new","","",3,[[["yaccgrammar",3],["stategraph",3]],[["statetableerror",3],["result",4]]]],[11,"action","","Return the action for <code>stidx</code> and <code>sym</code>, or <code>None</code> if there …",3,[[["tidx",3],["stidx",3]],["action",4]]],[11,"state_actions","","Return an iterator over the indexes of all non-empty …",3,[[["stidx",3]],["stateactionsiterator",3]]],[11,"state_shifts","","Return an iterator over the indexes of all shift actions …",3,[[["stidx",3]],["stateactionsiterator",3]]],[11,"reduce_only_state","","Does the state <code>stidx</code> 1) only contain reduce (and error) …",3,[[["stidx",3]]]],[11,"core_reduces","","Return an iterator over a set of \\\"core\\\" reduces of <code>stidx</code>. …",3,[[["stidx",3]],["corereducesiterator",3]]],[11,"goto","","Return the goto state for <code>stidx</code> and <code>ridx</code>, or <code>None</code> if …",3,[[["ridx",3],["stidx",3]],[["option",4],["stidx",3]]]],[11,"start_state","","Return this state table\'s start state.",3,[[],["stidx",3]]],[11,"conflicts","","Return a struct containing all conflicts or <code>None</code> if there …",3,[[],[["conflicts",3],["option",4]]]],[3,"StateActionsIterator","","",null,null],[3,"CoreReducesIterator","","",null,null],[3,"StateGraph","lrtable","",null,null],[6,"StIdxStorageT","","The type of the inner value of an StIdx.",null,null],[3,"StIdx","","StIdx is a wrapper for a state index. Its internal type …",null,null],[4,"Minimiser","","",null,null],[13,"Pager","","",5,null],[5,"from_yacc","","",null,[[["yaccgrammar",3],["minimiser",4]],[["result",4],["statetableerror",3]]]],[11,"from","","",6,[[]]],[11,"into","","",6,[[]]],[11,"borrow","","",6,[[]]],[11,"borrow_mut","","",6,[[]]],[11,"try_from","","",6,[[],["result",4]]],[11,"try_into","","",6,[[],["result",4]]],[11,"type_id","","",6,[[],["typeid",3]]],[11,"try_into","","",6,[[],["result",4]]],[11,"from","lrtable::statetable","",0,[[]]],[11,"into","","",0,[[]]],[11,"borrow","","",0,[[]]],[11,"borrow_mut","","",0,[[]]],[11,"try_from","","",0,[[],["result",4]]],[11,"try_into","","",0,[[],["result",4]]],[11,"type_id","","",0,[[],["typeid",3]]],[11,"try_into","","",0,[[],["result",4]]],[11,"from","","",1,[[]]],[11,"into","","",1,[[]]],[11,"borrow","","",1,[[]]],[11,"borrow_mut","","",1,[[]]],[11,"try_from","","",1,[[],["result",4]]],[11,"try_into","","",1,[[],["result",4]]],[11,"type_id","","",1,[[],["typeid",3]]],[11,"try_into","","",1,[[],["result",4]]],[11,"from","","",2,[[]]],[11,"into","","",2,[[]]],[11,"to_string","","",2,[[],["string",3]]],[11,"borrow","","",2,[[]]],[11,"borrow_mut","","",2,[[]]],[11,"try_from","","",2,[[],["result",4]]],[11,"try_into","","",2,[[],["result",4]]],[11,"type_id","","",2,[[],["typeid",3]]],[11,"try_into","","",2,[[],["result",4]]],[11,"from","","",3,[[]]],[11,"into","","",3,[[]]],[11,"borrow","","",3,[[]]],[11,"borrow_mut","","",3,[[]]],[11,"try_from","","",3,[[],["result",4]]],[11,"try_into","","",3,[[],["result",4]]],[11,"type_id","","",3,[[],["typeid",3]]],[11,"try_into","","",3,[[],["result",4]]],[11,"from","","",4,[[]]],[11,"into","","",4,[[]]],[11,"to_owned","","",4,[[]]],[11,"clone_into","","",4,[[]]],[11,"borrow","","",4,[[]]],[11,"borrow_mut","","",4,[[]]],[11,"try_from","","",4,[[],["result",4]]],[11,"try_into","","",4,[[],["result",4]]],[11,"type_id","","",4,[[],["typeid",3]]],[11,"try_into","","",4,[[],["result",4]]],[11,"from","","",7,[[]]],[11,"into","","",7,[[]]],[11,"into_iter","","",7,[[]]],[11,"borrow","","",7,[[]]],[11,"borrow_mut","","",7,[[]]],[11,"try_from","","",7,[[],["result",4]]],[11,"try_into","","",7,[[],["result",4]]],[11,"type_id","","",7,[[],["typeid",3]]],[11,"try_into","","",7,[[],["result",4]]],[11,"from","","",8,[[]]],[11,"into","","",8,[[]]],[11,"into_iter","","",8,[[]]],[11,"borrow","","",8,[[]]],[11,"borrow_mut","","",8,[[]]],[11,"try_from","","",8,[[],["result",4]]],[11,"try_into","","",8,[[],["result",4]]],[11,"type_id","","",8,[[],["typeid",3]]],[11,"try_into","","",8,[[],["result",4]]],[11,"from","lrtable","",9,[[]]],[11,"into","","",9,[[]]],[11,"to_owned","","",9,[[]]],[11,"clone_into","","",9,[[]]],[11,"borrow","","",9,[[]]],[11,"borrow_mut","","",9,[[]]],[11,"try_from","","",9,[[],["result",4]]],[11,"try_into","","",9,[[],["result",4]]],[11,"type_id","","",9,[[],["typeid",3]]],[11,"equivalent","","",9,[[]]],[11,"try_into","","",9,[[],["result",4]]],[11,"from","","",5,[[]]],[11,"into","","",5,[[]]],[11,"to_owned","","",5,[[]]],[11,"clone_into","","",5,[[]]],[11,"borrow","","",5,[[]]],[11,"borrow_mut","","",5,[[]]],[11,"try_from","","",5,[[],["result",4]]],[11,"try_into","","",5,[[],["result",4]]],[11,"type_id","","",5,[[],["typeid",3]]],[11,"try_into","","",5,[[],["result",4]]],[11,"from","","",9,[[["stidxstoraget",6]]]],[11,"from","","",10,[[["stidx",3]]]],[11,"next","lrtable::statetable","",7,[[],[["option",4],["tidx",3]]]],[11,"next","","",8,[[],[["pidx",3],["option",4]]]],[11,"clone","","",4,[[],["action",4]]],[11,"clone","lrtable","",9,[[],["stidx",3]]],[11,"clone","","",5,[[],["minimiser",4]]],[11,"eq","lrtable::statetable","",4,[[["action",4]]]],[11,"ne","","",4,[[["action",4]]]],[11,"eq","lrtable","",9,[[["stidx",3]]]],[11,"ne","","",9,[[["stidx",3]]]],[11,"fmt","","",6,[[["formatter",3]],["result",6]]],[11,"fmt","lrtable::statetable","",0,[[["formatter",3]],["result",6]]],[11,"fmt","","",1,[[["formatter",3]],["result",6]]],[11,"fmt","","",2,[[["formatter",3]],["result",6]]],[11,"fmt","","",4,[[["formatter",3]],["result",6]]],[11,"fmt","lrtable","",9,[[["formatter",3]],["result",6]]],[11,"fmt","lrtable::statetable","",2,[[["formatter",3]],["result",6]]],[11,"hash","lrtable","",9,[[]]],[11,"serialize","lrtable::statetable","",0,[[],["result",4]]],[11,"serialize","","",3,[[],["result",4]]],[11,"serialize","","",4,[[],["result",4]]],[11,"serialize","lrtable","",9,[[],["result",4]]],[11,"deserialize","lrtable::statetable","",0,[[],["result",4]]],[11,"deserialize","","",3,[[],["result",4]]],[11,"deserialize","","",4,[[],["result",4]]],[11,"deserialize","lrtable","",9,[[],["result",4]]],[11,"start_state","","Return this state graph\'s start state.",6,[[],["stidx",3]]],[11,"iter_stidxs","","Return an iterator which produces (in order from …",6,[[],[["iterator",8],["box",3]]]],[11,"closed_state","","Return the itemset for closed state <code>stidx</code>. Panics if <code>stidx</code>…",6,[[["stidx",3]],["itemset",3]]],[11,"iter_closed_states","","Return an iterator over all closed states in this …",6,[[],[["box",3],["iterator",8]]]],[11,"core_state","","Return the itemset for core state <code>stidx</code> or <code>None</code> if it …",6,[[["stidx",3]],["itemset",3]]],[11,"iter_core_states","","Return an iterator over all core states in this <code>StateGraph</code>…",6,[[],[["box",3],["iterator",8]]]],[11,"all_states_len","","How many states does this <code>StateGraph</code> contain? NB: By …",6,[[],["stidx",3]]],[11,"edge","","Return the state pointed to by <code>sym</code> from <code>stidx</code> or <code>None</code> …",6,[[["symbol",4],["stidx",3]],[["option",4],["stidx",3]]]],[11,"edges","","Return the edges for state <code>stidx</code>. Panics if <code>stidx</code> doesn\'t …",6,[[["stidx",3]],["hashmap",3]]],[11,"all_edges_len","","How many edges does this <code>StateGraph</code> contain?",6,[[]]],[11,"pp","","Pretty print this stategraph as a <code>String</code>. If <code>core_states</code> …",6,[[["yaccgrammar",3]],["string",3]]],[11,"pp_core_states","","Return a pretty printed version of the core states, and …",6,[[["yaccgrammar",3]],["string",3]]],[11,"pp_closed_states","","Return a pretty printed version of the closed states, and …",6,[[["yaccgrammar",3]],["string",3]]]],"p":[[3,"Conflicts"],[4,"StateTableErrorKind"],[3,"StateTableError"],[3,"StateTable"],[4,"Action"],[4,"Minimiser"],[3,"StateGraph"],[3,"StateActionsIterator"],[3,"CoreReducesIterator"],[3,"StIdx"],[6,"StIdxStorageT"]]}\
}');
addSearchOptions(searchIndex);initSearch(searchIndex);